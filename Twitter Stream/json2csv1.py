import json
import csv
import collections
import re

## this script take output.json(generated by twitterstream.py) as input file and output tweettext.csv as output file

def toLowercase(text):
	return text.lower()
def removeLinks(text):
	URLless_string = re.sub(r'\w+:\/{2}[\d\w-]+(\.[\d\w-]+)*(?:(?:\/[^\s/]*))*', '', text)
	return URLless_string
def removePunc(text):
	punc=(",./;():'?&-!")
	strp = text.translate(None, punc)
	return strp
def nonascii(file):
	return text
def removeCommon(text,filename):
	reference1 = create_data_lists_common(filename)
	for item in reference1:
		text = text.replace(str(item),"")
	return text
def removeStop(text,filename):
	reference2 = create_data_lists_stop(filename)
	#text = [re.sub('|'.join(stop_words),'',stop) for stop in reference2]
	return text
def removeCommon1(text,filename):
	reference1 = create_data_lists_common(filename)
	return " ".join(word for word in text.split() if word not in reference1)
def removeStop1(text,filename):
	reference2 = create_data_lists_stop(filename)
	return " ".join(word for word in text.split() if word not in reference2)
def removeat(text):
		cleantext = re.sub(r'@([A-Za-z0-9_]+)',"",text).strip()
		return cleantext
def create_data_lists_common(filename):
	
	with open(filename+'.csv', 'r') as f:
		#print filename
		rowdata = []
		reader = csv.reader(f)
		reader.next()
		for row in reader:
			rowdata.append(row)
	common.append(rowdata)
	return common
def create_data_lists_stop(filename):
	
	with open(filename+'.csv', 'r') as f:
		#print filename
		rowdata = []
		reader = csv.reader(f)
		reader.next()
		for row in reader:
			rowdata.append(row)
	stop.append(rowdata)
	return stop

common = []
stop = []
data_by_csv =[]
f = open("processed\\output.txt", "r")
#csv = open("removetweetpy.csv","r")
w = open("tweet2csv.csv",'wb')
writer = csv.writer(w)

none = "null"
i = 1
writer.writerow(["created_time", "tweet_id", "user_name", "tweet_text"])
for item in f.readlines():
	d = collections.defaultdict(list)
	data = json.loads(item)
	
	try:

		if data["lang"] == 'en': #only english tweets will be displayed
			if 'created_at' in data:
				if(len(data["created_at"]) > 0):
					d["created_at"].append(data["created_at"])
			else: d["created_at"].append(none)

			if 'id' in data:
				if(len(str(data["id"])) > 0):
					d["id"].append(str(data["id"]))
			else: d["id"].append(none)

			if 'text' in data:
				if(len(data["text"]) > 0):
					tweets = data["text"].encode('utf-8')
					tweets = removeLinks(tweets)
					#remove common word based on the given filename 
					#tweets = removeCommon(tweets,'removetweepy')
					#remove stop word from given filename
					#tweets = removeStop(tweets,'stopwords')
					tweets = removeat(tweets)
					tweets = toLowercase(tweets)
					tweets = removePunc(tweets)
					#remove common word based on the given filename 
					#tweets = removeCommon(tweets,'removetweepy')
					#remove stop word from given filename
					#tweets = removeStop(tweets,'stopwords')

					d["text"].append(tweets)
			else: d["text"].append(none)

			if 'screen_name' in data['user']:
				if(len(data["user"]["screen_name"]) > 0):
					d["screen_name"].append(data["user"]["screen_name"])
				else: d["screen_name"].append(none)

			writer.writerow([d["created_at"][0],d["id"][0],d["screen_name"][0],d["text"][0]])
			i = i + 1
			print i
			## uncomment this to display language specification on 4th column

			#if 'lang' in data:
			#	d["lang"].append(data["lang"])
			#else: d["lang"].append(none)

			## uncomment this to display user id, user_follower_count etc.
			
			#	if 'description' in data["user"]:
			#		d["description"].append(data["user"]["description"])
			#	else: d["description"].append(none)
			#
			#	if 'followers_count' in data["user"]:
			#		d["followers_count"].append(data["user"]["followers_count"])
			#	else: d["followers_count"].append(none)
			#
			#	if 'friends_count' in data["user"]:
			#		d["friends_count"].append(data["user"]["friends_count"])
			#	if 'time_zone' in data["user"]:
			#		d["time_zone"].append(data["user"]["time_zone"])
			#	else: d["time_zone"].append(none)
			#
			#	if 'lang' in data["user"]:
			#		d["lang"].append(data["user"]["lang"])
			#	else: d["lang"].append(none)
			#	print data["user"]["lang"]

	except KeyError as err:
		print "lang not exists"




